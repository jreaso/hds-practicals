{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b8ac1ea-8697-4131-837c-ef4254d38491",
   "metadata": {},
   "source": [
    "# Practical 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c08831-afad-4c59-b72d-d55e2b0a28df",
   "metadata": {},
   "source": [
    "## Question 2.1\n",
    "\n",
    "This practical question aims to analyse a high dimensional microarray data set called `eyedata`, available on Ultra, which contains gene expression data of 200 genes for 120 samples, along with the `TRIM32` gene of 120 samples as the response variable of interest. The data originates from microarray experiments of mammalian eye tissue samples. The first variable (column) in data is the `TRIM32` gene as the response variable, and the other variables (columns) are the 200 genes as the covariates, quantified for 120 samples (observations in rows).\n",
    "\n",
    "The main objectives of this study were to find out which genes are associated with the `TRIM32` and to predict the expression levels of `TRIM32` from the expression levels of the 200 genes measured in the microarray experiment.\n",
    "\n",
    "**a)** Load the eyedata into R using the command `load(file=\"eyedata.rda\")`. Note that you may need to paste the right directory of the data file in your computer. For example, `load(file=\"C:/Users/bvft24/Desktop/eyedata.rda\")`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54d8696-8e68-4b67-80df-5c9d00206568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95339f58-be57-46c8-bb90-ef4b5cfd8b18",
   "metadata": {},
   "source": [
    "**b)** In R, create the response variable vector $\\boldsymbol{Y}$ being the first column of eyedata. Also, create the covariates design matrix $\\boldsymbol{X}$ being all columns of eyed ata except the first column. Do centre both $\\boldsymbol{Y}$ and $\\boldsymbol{X}$ using the $\\mathrm{R}$ function scale so that all the covariates and the response variable have zero mean (no need to scale them having variance 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f546bc2-15f4-41c6-82d0-ed78b9ae9a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02efc129-958d-4ef2-88b9-8699216a5453",
   "metadata": {},
   "source": [
    "**c)** Consider a linear regression model with $\\boldsymbol{Y}$ and $\\boldsymbol{X}$. Show that the OLS method fails to work here. For this, first show that $\\boldsymbol{X}$ does not have full column rank by computing the rank of $\\boldsymbol{X}$ using the $\\mathrm{R}$ function `qr`. Then calculate the inverse of matrix $\\boldsymbol{X}^T \\boldsymbol{X}$ using the $\\mathrm{R}$ function `solve` and observe that the inverse does not exist due to singularity as $n<p$. Despite the OLS does not work properly, apply it using the $R$ function `lm` and interpret what goes wrong in the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf542ff-6843-4db4-b2fe-8501b7437f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cedb0e75-8cb9-4f5f-b9cf-7937890d9b6c",
   "metadata": {},
   "source": [
    "**d)** Apply the ridge regression model with $\\boldsymbol{Y}$ and $\\boldsymbol{X}$ using the R function `glmnet` with the regularisation parameter set to $\\lambda=2$. You may need to first install the R package `glmnet` and load it in R using the following commands:\n",
    "```r\n",
    "install.packages(\"glmnet\")\n",
    "library(glmnet)\n",
    "```\n",
    "For this case of $\\lambda=2$, extract the ridge estimates of regression coefficients $\\boldsymbol{\\beta}$ using the R function `coef`.\n",
    "\n",
    "Now, choose an optimal value of $\\lambda$ for ridge regression by applying the cross validation (CV) using the R function `cv.glmnet` which by default minimises the deviance. Plot the CV output using the R function `plot`. Fit the ridge regression model to the data with this optimal value of $\\lambda$ and extract the estimates of regression coefficients $\\boldsymbol{\\beta}$. What do you observe when comparing the estimates with the previous case of $\\lambda=2$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2496ecd0-661b-4efd-a144-236f1e29c2a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1450ab8-7a38-4e7d-b0e9-56c16b6e0545",
   "metadata": {},
   "source": [
    "**e)** Apply the lasso regression with $\\boldsymbol{Y}$ and $\\boldsymbol{X}$ using the R function `glmnet` with an optimal value of $\\lambda$ being chosen using the cross validation with the R function `cv.glmnet`. Plot the CV output using the R function `plot`. Extract the lasso estimates of parameters $\\boldsymbol{\\beta}$ and compare with the ridge estimates in terms of the sparsity of solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae677bc-f7a4-44bd-a4fe-8d6fbc3bba3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1259036-6f64-4cb7-ab81-0387aabb6713",
   "metadata": {},
   "source": [
    "**f)** Randomly partition the data to training data $\\left(70 \\%\\right.$, say $\\boldsymbol{Y}_{\\text {train }}$ and $\\left.\\boldsymbol{X}_{\\text {train }}\\right)$ and test data (30\\%, say $\\boldsymbol{Y}_{\\text {test }}$ and $\\left.\\boldsymbol{X}_{\\text {test }}\\right)$. Apply ridge and lasso regression to the training data, both with $\\lambda$ being chosen by $\\mathrm{CV}$, and then use the fitted models to predict the response values in the test data. Calculate the mean squared error of predictions for the two methods and comment which method provides better predictions and discuss why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f5757d-7075-41d4-b3a1-1d2dd04d64ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13a8b826-ce26-4caf-8ef9-680b49ee67e5",
   "metadata": {},
   "source": [
    "## Question 2.2\n",
    "\n",
    "Consider the high dimensional data set called `riboflavin`, available on Ultra, which is obtained from a high-throughput genomic study concerning the riboflavin (vitamin $B_2$ ) production by bacillus subtilis. The main objective of the study was to find out which genes are associated with the production rate of vitamin $B_2$. The data set contains 71 samples and 4088 covariates corresponding to 4088 genes, along with the logarithm of riboflavin production rate as response variable.\n",
    "\n",
    "**a)** First, load the `riboflavin` data into R environment using the command `load(file=\"riboflavin.rda\")`. Again you might need to specify the right directory of the data file in your computer. Then, create the response variable vector $\\boldsymbol{Y}$ from this data set using the command `Y <- rib of lavin\\$y`. Also, create the covariates design matrix $\\boldsymbol{X}$ using the command `X<-$ riboflavin$x`. Center the covariates $\\boldsymbol{X}$ to have zero mean but not the response variable $\\boldsymbol{Y}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbdf18e-10a1-450b-891f-8cf6a61d6c46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77b33221-1854-41f5-aa81-5a5556a85f29",
   "metadata": {},
   "source": [
    "**b)** Calculate the pairwise correlations between covariates (or genes) to see if they are correlated. For this, use the R function `cor`. Create a histogram of the pairwise correlations using the R function `hist`. What do you observe here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b9f9af-affc-4b3d-ba70-84636bb29735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5c2f278-8617-478c-956d-13e70cf6c711",
   "metadata": {},
   "source": [
    "**c)** Apply the ridge and lasso regression to the `riboflavin` data, both with $\\lambda$ being chosen by CV. Interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f250260-6f93-4845-8724-e6e6816cc9fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a47e5a6-8274-4c40-bb6e-85d902b6e492",
   "metadata": {},
   "source": [
    "**d)** Randomly partition the data to training data (70\\%, say $\\boldsymbol{Y}_{\\text {train }}$ and $\\boldsymbol{X}_{\\text {train }}$ ) and test data (30\\%, say $\\boldsymbol{Y}_{\\text {test }}$ and $\\left.\\boldsymbol{X}_{\\text {test }}\\right)$. Apply ridge and lasso regression to the training data and then use the fitted models to predict the response values in the test data. Calculate the mean squared error of predictions for the two methods and discuss which method provides better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b080afd1-df19-4c5b-90e9-cd7bbdc176f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cdcafb6-6b8d-42ed-b78f-9a08bde4307e",
   "metadata": {},
   "source": [
    "**e)** Note that this and the next parts of question could be tried later as they concern \"elastic net regularisation\" for correlated variables which will be covered at the end of Chapter 2. In R package `glmnet`, for computational convenience, the elastic net estimator is defined as\n",
    "$$\\hat{\\boldsymbol{\\beta}}_{\\mathrm{EN}}=\\underset{\\boldsymbol{\\beta} \\in \\mathbb{R}^p}{\\operatorname{argmin}}\\left\\{1 / n\\|\\boldsymbol{Y}-\\boldsymbol{X} \\boldsymbol{\\beta}\\|_2^2+\\alpha\\|\\boldsymbol{\\beta}\\|_1^1+(1-\\alpha) / 2\\|\\boldsymbol{\\beta}\\|_2^2\\right\\}$$\n",
    "in which $0 \\leq \\alpha \\leq 1$ is a single regularisation parameter. Note that $\\alpha=1$ results in the lasso penalty and $\\alpha=0$ leads to the ridge penalty. Note also that the factor $1 / n$ is just a normalising constant.\n",
    "\n",
    "Setting $\\alpha=0.5$ in `glmnet`, apply the elastic net to the `riboflavin` data and extract the parameter estimates. What are the estimates with $\\alpha=0.8 ?$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba3a1b7-9f29-44cd-812f-a537d95b83db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cfed1bc-dc7d-47d2-8cd1-5dcf4420e39f",
   "metadata": {},
   "source": [
    "**f)** Use cross validation to find an optimal value of $\\alpha$ for the elastic net. For this, consider a range of values for $\\alpha$, say $\\alpha=i / 20$ for $i=0,1, \\ldots, 20$, and investigate which one of these $\\alpha$ values results in smallest prediction error when applied to randomly selected training $(70 \\%)$ and test $(30 \\%)$ data. Can this be related to the correlations among genes investigated in Part (b)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f48c649-8a93-4218-9071-7c23ba5abbc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
